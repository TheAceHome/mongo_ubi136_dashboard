# Архитектура системы UBI.136 Protection

## Общая схема

```
┌─────────────────────────────────────────────────────────────┐
│                    Клиентское приложение                     │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│              Consensus Service (8001) - ГЛАВНЫЙ              │
│  • Управление writeConcern/readConcern                       │
│  • Валидация операций перед выполнением                      │
│  • Координация защитных механизмов                           │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│              MongoDB Replica Set (3 узла)                    │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │ mongo-primary│  │mongo-secondary│  │mongo-secondary│      │
│  │    :27017    │  │    :27018     │  │    :27019     │      │
│  │   PRIMARY    │  │  SECONDARY    │  │  SECONDARY    │      │
│  └──────┬───────┘  └──────┬────────┘  └──────┬────────┘      │
│         │                 │                   │               │
│         └─────────────────┴───────────────────┘               │
│                  Raft Consensus                               │
│                  Oplog Replication                            │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────┐
│              Защитные микросервисы                           │
│                                                              │
│  ┌────────────────────────────────────────────────────┐     │
│  │  Replication Monitoring (8002)                     │     │
│  │  • Мониторинг oplog lag                           │     │
│  │  • Детекция отставания репликации                 │     │
│  │  • Алерты о проблемах                             │     │
│  └────────────────────────────────────────────────────┘     │
│                                                              │
│  ┌────────────────────────────────────────────────────┐     │
│  │  Health Check Service (8003)                       │     │
│  │  • Проверка доступности узлов                     │     │
│  │  • Детекция Split-Brain                           │     │
│  │  • Оценка состояния кластера                      │     │
│  └────────────────────────────────────────────────────┘     │
│                                                              │
│  ┌────────────────────────────────────────────────────┐     │
│  │  Transaction Log Service (8004)                    │     │
│  │  • Логирование всех операций                      │     │
│  │  • Аудит транзакций                               │     │
│  │  • Анализ истории изменений                       │     │
│  └────────────────────────────────────────────────────┘     │
│                                                              │
│  ┌────────────────────────────────────────────────────┐     │
│  │  Recovery Service (8005)                           │     │
│  │  • Автоматическая ресинхронизация                 │     │
│  │  • Обработка rollback                             │     │
│  │  • Восстановление узлов                           │     │
│  └────────────────────────────────────────────────────┘     │
└─────────────────────────────────────────────────────────────┘
```

---

## Компоненты системы

### 1. MongoDB Replica Set

**Роль:** Распределенное хранилище данных с репликацией

**Узлы:**
- **mongo-primary** (порт 27017) - Primary узел, принимает все записи
- **mongo-secondary1** (порт 27018) - Secondary узел, реплика данных
- **mongo-secondary2** (порт 27019) - Secondary узел, реплика данных

**Механизмы защиты:**
- **Raft Consensus Protocol** - алгоритм выбора Primary узла
- **Oplog (Operations Log)** - журнал операций для репликации
- **Write Concern: majority** - запись с подтверждением от большинства
- **Read Concern: majority** - чтение только признанных данных

---

### 2. Consensus Service (порт 8001) 🛡️ ГЛАВНЫЙ

**Назначение:** Основной защитный сервис, управляющий согласованностью данных

**Основные функции:**

#### 2.1 Безопасная запись (POST /write/safe)
```python
writeConcern: "majority"  # Требует подтверждения от большинства узлов
```
- Гарантирует запись на минимум 2 из 3 узлов
- Предотвращает потерю данных при отказе узла
- Блокирует операцию если нет кворума

#### 2.2 Валидация операций (POST /validate/operation)
- Проверка наличия Primary узла
- Проверка доступности кворума узлов
- Анализ текущего состояния кластера
- Решение о допустимости операции

#### 2.3 Безопасное чтение (GET /read/safe)
```python
readConcern: "majority"  # Читает только согласованные данные
```
- Исключает чтение из отстающих Secondary
- Гарантирует актуальность данных

**Защита от UBI.136:**
- ✅ Предотвращение записи несогласованных данных
- ✅ Гарантия записи на большинство узлов
- ✅ Блокировка операций при проблемах с кластером

---

### 3. Replication Monitoring Service (порт 8002)

**Назначение:** Мониторинг процесса репликации и обнаружение проблем

**Основные метрики:**

#### 3.1 Oplog Lag (GET /replication/lag)
```
Primary Optime:    2024-01-01 12:00:00
Secondary Optime:  2024-01-01 11:59:55
Lag:               5 секунд ✅ GOOD
```

**Классификация задержки:**
- **< 5s:** EXCELLENT - отличная синхронизация
- **5-10s:** GOOD - нормальная задержка
- **10-30s:** WARNING - повышенная задержка
- **> 30s:** CRITICAL - критическая задержка

#### 3.2 Активные алерты (GET /monitoring/alerts)

**Типы алертов:**
- 🔴 **NO_PRIMARY** - отсутствует Primary узел
- 🔴 **SPLIT_BRAIN** - обнаружено >1 Primary
- ⚠️ **UNHEALTHY_NODE** - узел недоступен
- ⚠️ **HIGH_REPLICATION_LAG** - высокая задержка репликации

**Защита от UBI.136:**
- ✅ Раннее обнаружение проблем репликации
- ✅ Мониторинг расхождения данных между узлами
- ✅ Предупреждение о критических ситуациях

---

### 4. Health Check Service (порт 8003)

**Назначение:** Проверка состояния и доступности узлов кластера

**Проверки:**

#### 4.1 Проверка всех узлов (GET /health/all)
```json
{
  "cluster_status": "HEALTHY",
  "healthy_nodes": 3,
  "unhealthy_nodes": 0,
  "health_percentage": 100
}
```

#### 4.2 Проверка Primary (GET /health/primary)
```json
{
  "status": "HEALTHY",
  "primary_node": {
    "name": "mongo-primary:27017",
    "health": "healthy"
  }
}
```

#### 4.3 Детекция Split-Brain
```json
{
  "status": "CRITICAL",
  "message": "Обнаружено более одного Primary узла!",
  "primary_nodes": ["mongo-primary", "mongo-secondary1"],
  "threat": "Критический риск расхождения данных"
}
```

**Защита от UBI.136:**
- ✅ Детекция Split-Brain сценария
- ✅ Проверка доступности узлов
- ✅ Оценка риска потери данных

---

### 5. Transaction Log Service (порт 8004)

**Назначение:** Логирование и аудит всех операций

**Что логируется:**
```json
{
  "timestamp": "2024-01-01T12:00:00Z",
  "operation_type": "insert",
  "target_collection": "test_data",
  "write_concern": "majority",
  "result": "success",
  "replica_set_status": {
    "primary": "mongo-primary",
    "healthy_nodes": 3
  }
}
```

**Функции:**

#### 5.1 Аудит операций (GET /audit/timeline)
- История всех операций записи
- Временная линия изменений
- Анализ неудачных операций

#### 5.2 Статистика (GET /logs/stats)
- Количество операций по типам
- Использование writeConcern
- Процент успешных операций

**Защита от UBI.136:**
- ✅ Полный аудит всех операций
- ✅ Возможность отследить потерянные данные
- ✅ Анализ причин сбоев

---

### 6. Recovery Service (порт 8005)

**Назначение:** Автоматическое восстановление и синхронизация узлов

**Функции:**

#### 6.1 Детекция проблем (GET /recovery/status)
```json
{
  "nodes_needing_recovery": [
    {
      "name": "mongo-secondary1",
      "issue": "High replication lag: 120s",
      "recovery_needed": true
    }
  ]
}
```

#### 6.2 Автовосстановление (POST /recovery/auto-heal)
- Автоматическая ресинхронизация отставших узлов
- Обработка rollback ситуаций
- Восстановление после сбоев

#### 6.3 Рекомендации (GET /recovery/recommendations)
```json
{
  "recommendations": [
    {
      "priority": "HIGH",
      "issue": "Нет Secondary узлов",
      "recommendation": "Восстановите Secondary для репликации",
      "impact": "Нет защиты от UBI.136"
    }
  ]
}
```

**Защита от UBI.136:**
- ✅ Автоматическое восстановление узлов
- ✅ Предотвращение расхождения данных
- ✅ Обработка rollback для сохранения консистентности

---

## Сценарии угрозы и защиты

### Сценарий 1: Отключение Secondary узла

**Атака:**
```bash
docker stop mongo-secondary1
```

**Что происходит:**
1. Health Check Service детектирует отключение узла
2. Replication Monitoring выдает алерт о потере избыточности
3. Consensus Service продолжает работу, т.к. кворум (2/3) сохранен
4. WriteConcern:majority обеспечивает запись на Primary + Secondary2

**Защита:** ✅ Данные защищены, потери нет

**Восстановление:**
```bash
docker start mongo-secondary1
# Recovery Service автоматически синхронизирует данные
```

---

### Сценарий 2: Сетевая изоляция (Split-Brain)

**Атака:**
```bash
# Изолируем Primary от Secondary узлов
docker network disconnect mongo-network mongo-primary
```

**Что происходит:**
1. Secondary узлы теряют связь с Primary
2. Raft-протокол запускает выборы нового Primary
3. Один из Secondary становится новым Primary
4. Старый Primary обнаруживает потерю кворума и переходит в SECONDARY

**Защита:**
- ✅ Raft-протокол не позволяет создать 2 Primary
- ✅ WriteConcern:majority блокирует записи без кворума
- ✅ Health Check детектирует проблему

**Альтернативный сценарий (худший):**
Если сеть разделилась так, что каждая часть думает, что у неё есть кворум:
- Consensus Service заблокирует операции
- Health Check выдаст CRITICAL алерт
- Recovery Service предложит рекомендации

---

### Сценарий 3: Rollback ситуация

**Когда возникает:**
1. Secondary узел отключился от сети
2. На нем были записи, которые еще не реплицировались
3. Узел переподключился, но Primary уже другой
4. Нереплицированные данные несогласованы с кластером

**Защита:**
- ✅ MongoDB автоматически откатывает несогласованные записи
- ✅ Откатываемые данные сохраняются в rollback файлы
- ✅ Recovery Service обрабатывает ситуацию
- ✅ WriteConcern:majority предотвращает такие ситуации

---

## Взаимодействие компонентов

### Последовательность безопасной записи

```
1. Клиент → Consensus Service: POST /write/safe
                │
                ▼
2. Consensus Service: Валидация кластера
   - Проверка Primary узла
   - Проверка кворума
   - Проверка здоровья узлов
                │
                ▼
3. Consensus Service → MongoDB: Insert с writeConcern:majority
                │
                ├─→ Primary: Записывает данные
                │            │
                │            ├─→ Secondary1: Реплицирует
                │            └─→ Secondary2: Реплицирует
                │
                ▼
4. MongoDB → Consensus Service: Acknowledgment (2/3 узлов подтвердили)
                │
                ▼
5. Consensus Service → Transaction Log: Логировать операцию
                │
                ▼
6. Consensus Service → Клиент: Success ✅
```

### Мониторинг (параллельный процесс)

```
Постоянно:
  Replication Monitoring → MongoDB: Проверка oplog lag
  Health Check → MongoDB: Проверка узлов
  Recovery Service → MongoDB: Проверка синхронизации
             │
             ▼
  При обнаружении проблемы → Алерт → Логирование → Автовосстановление
```

---

## Технологический стек

- **MongoDB 5.0+** - Распределенная база данных
- **Python 3.11** - Язык программирования
- **FastAPI** - Web framework для микросервисов
- **PyMongo** - MongoDB драйвер
- **Docker & Docker Compose** - Контейнеризация
- **Uvicorn** - ASGI сервер

---

## Метрики защиты

### Уровни защиты от UBI.136

| Ситуация | Healthy nodes | WriteConcern | Защита | Риск |
|----------|---------------|--------------|--------|------|
| Все узлы работают | 3/3 | majority | ✅ FULL | NONE |
| 1 Secondary down | 2/3 | majority | ✅ GOOD | LOW |
| 2 узла down | 1/3 | majority | ⚠️ DEGRADED | HIGH |
| Нет Primary | N/A | N/A | 🔴 NONE | CRITICAL |
| Split-Brain | N/A | N/A | 🔴 NONE | CRITICAL |

---

## Выводы

Система UBI.136 Protection обеспечивает **многоуровневую защиту** от потери данных:

1. **Репликация** - 3 копии данных
2. **WriteConcern** - гарантированная запись на большинство
3. **ReadConcern** - чтение только согласованных данных
4. **Raft Consensus** - защита от Split-Brain
5. **Мониторинг** - раннее обнаружение проблем
6. **Автовосстановление** - автоматическая синхронизация

**Результат:** Данные защищены даже при отказе узлов и сетевых проблемах ✅
